apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
  labels:
    app: postgres
spec:
  serviceName: postgres
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:14-alpine
        ports:
        - containerPort: 5432
          name: postgres
        env:
        - name: POSTGRES_DB
          value: easybank
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: easybank-secrets
              key: db-username
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: easybank-secrets
              key: db-password
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
        volumeMounts:
        - name: postgres-data
          mountPath: /var/lib/postgresql/data
      volumes:
      - name: postgres-data
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: postgres
  labels:
    app: postgres
spec:
  ports:
  - port: 5432
    targetPort: 5432
    name: postgres
  selector:
    app: postgres
  type: ClusterIP
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: db-migration-config
data:
  flyway.conf: |
    flyway.url=jdbc:postgresql://${DB_HOST}:${DB_PORT}/${DB_NAME}
    flyway.user=${DB_USER}
    flyway.password=${DB_PASSWORD}
    flyway.schemas=public
    flyway.baselineOnMigrate=true
    flyway.locations=classpath:db/migration
---
apiVersion: batch/v1
kind: Job
metadata:
  name: db-migration
  annotations:
    "helm.sh/hook": pre-install,pre-upgrade
    "helm.sh/hook-weight": "0"
    "helm.sh/hook-delete-policy": hook-succeeded
spec:
  backoffLimit: 5
  template:
    spec:
      containers:
      - name: flyway
        image: flyway/flyway:9-alpine
        command: ["flyway", "migrate"]
        env:
        - name: DB_HOST
          valueFrom:
            configMapKeyRef:
              name: easybank-config
              key: db-host
        - name: DB_PORT
          valueFrom:
            configMapKeyRef:
              name: easybank-config
              key: db-port
        - name: DB_NAME
          valueFrom:
            configMapKeyRef:
              name: easybank-config
              key: db-name
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: easybank-secrets
              key: db-username
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: easybank-secrets
              key: db-password
        volumeMounts:
        - name: config-volume
          mountPath: /flyway/conf
        - name: sql-volume
          mountPath: /flyway/sql
      volumes:
      - name: config-volume
        configMap:
          name: db-migration-config
      - name: sql-volume
        configMap:
          name: db-migration-sql
      restartPolicy: OnFailure
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: db-migration-sql
data:
  V1__initial_schema.sql: |
    CREATE TABLE IF NOT EXISTS public.accounts (
        id BIGSERIAL PRIMARY KEY,
        account_number VARCHAR(50) UNIQUE NOT NULL,
        account_holder VARCHAR(100) NOT NULL,
        balance DECIMAL(19,2) NOT NULL DEFAULT 0.00,
        currency VARCHAR(3) NOT NULL DEFAULT 'USD',
        account_type VARCHAR(20) NOT NULL,
        status VARCHAR(20) NOT NULL DEFAULT 'ACTIVE',
        version INTEGER NOT NULL DEFAULT 0,
        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
    );

    CREATE TABLE IF NOT EXISTS public.transactions (
        id BIGSERIAL PRIMARY KEY,
        source_account_id BIGINT REFERENCES accounts(id),
        destination_account_id BIGINT REFERENCES accounts(id),
        amount DECIMAL(19,2) NOT NULL,
        currency VARCHAR(3) NOT NULL,
        transaction_type VARCHAR(20) NOT NULL,
        status VARCHAR(20) NOT NULL DEFAULT 'PENDING',
        description TEXT,
        version INTEGER NOT NULL DEFAULT 0,
        created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
        CONSTRAINT chk_different_accounts CHECK (source_account_id != destination_account_id),
        CONSTRAINT chk_positive_amount CHECK (amount > 0)
    );

    CREATE INDEX IF NOT EXISTS idx_accounts_account_number ON public.accounts(account_number);
    CREATE INDEX IF NOT EXISTS idx_accounts_status ON public.accounts(status);
    CREATE INDEX IF NOT EXISTS idx_transactions_source_account ON public.transactions(source_account_id);
    CREATE INDEX IF NOT EXISTS idx_transactions_destination_account ON public.transactions(destination_account_id);
    CREATE INDEX IF NOT EXISTS idx_transactions_created_at ON public.transactions(created_at);

  V2__add_transaction_id.sql: |
    ALTER TABLE public.transactions ADD COLUMN IF NOT EXISTS transaction_id VARCHAR(50);
    CREATE INDEX IF NOT EXISTS idx_transactions_transaction_id ON public.transactions(transaction_id);
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: db-backup
spec:
  schedule: "0 1 * * *"  # Run daily at 1 AM UTC
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: postgres:14-alpine
            command:
            - /bin/sh
            - -c
            - |
              echo "Starting database backup at $(date)"
              BACKUP_FILE="easybank_$(date +%Y%m%d_%H%M%S).sql.gz"
              PGPASSWORD=$DB_PASSWORD pg_dump -h $DB_HOST -p $DB_PORT -U $DB_USER $DB_NAME | gzip > /backups/$BACKUP_FILE
              echo "Backup completed: $BACKUP_FILE"
              
              # If using AWS S3 for backup storage
              if [ -n "$AWS_ACCESS_KEY_ID" ]; then
                echo "Uploading backup to S3"
                aws s3 cp /backups/$BACKUP_FILE s3://$S3_BUCKET/backups/$BACKUP_FILE
                echo "S3 upload completed"
              fi
              
              # Cleanup old backups (keep last 7 days)
              find /backups -type f -name "easybank_*.sql.gz" -mtime +7 -delete
            env:
            - name: DB_HOST
              valueFrom:
                configMapKeyRef:
                  name: easybank-config
                  key: db-host
            - name: DB_PORT
              valueFrom:
                configMapKeyRef:
                  name: easybank-config
                  key: db-port
            - name: DB_NAME
              valueFrom:
                configMapKeyRef:
                  name: easybank-config
                  key: db-name
            - name: DB_USER
              valueFrom:
                secretKeyRef:
                  name: easybank-secrets
                  key: db-username
            - name: DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: easybank-secrets
                  key: db-password
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: aws-credentials
                  key: access-key-id
                  optional: true
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: aws-credentials
                  key: secret-access-key
                  optional: true
            - name: S3_BUCKET
              valueFrom:
                configMapKeyRef:
                  name: backup-config
                  key: s3-bucket
                  optional: true
            volumeMounts:
            - name: backup-volume
              mountPath: /backups
          volumes:
          - name: backup-volume
            persistentVolumeClaim:
              claimName: backup-pvc
          restartPolicy: OnFailure
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: backup-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi 